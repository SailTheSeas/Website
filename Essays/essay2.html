<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Essay about UX and UI Analysis done on a South African Website">
    <meta name="author" content="Suhail Jadwat">
    <meta name="keywords" content="Photography, Website, Products, UX Analysism, UI Analysis">
    <title>Essays</title>
    <link rel="stylesheet" href="../CSS/style.css">
    <link rel="stylesheet" href="../CSS/blog.css">
    <script type="module">
        import { initialise } from "../JavaScript/menu.js"
        initialise("essay")</script>

</head>

<body>
    <header>
        <h1 class="label">Sail's Ship</h1>

        <nav>
        </nav>

    </header>

    <div class="content">
        <h1 class="title">Essay 2: Digital Colonialism and the Global South</h1>

        <h2>Introduction</h2>
        <p>
            Digital colonialism is the idea of control of a nation through digital technology and is a rampant force in the digital era,
            as defined by Sareeta Amrute. In the same paper, Amrute talks about predictive software being misused to discriminate against black people within the US,
            which can still be seen within modern day AI system, and is also a reflection of the diversity, or lack thereof, within these tech industries.
            With many big tech companies moving their work force overseas to the “Global South”, this gap in representation can be closed,
            even though these jobs are meant to exploit the same people.
        </p>

        <h2>AI Models</h2>

        <p>
            Many ai based technology have shown biases in their work,
            whether it be ai art reinforcing stereotypes [1] or predictive searches producing clearly biased prompts [2].
            Through many users experience with generative art, it has been seen that there is a tendency to prefer lighter skinned depictions of people,
            especially when it comes to beauty [3]. It is also found that when generating art pertaining to subject, such as productivity,
            the results would be biased heavily towards white males [1]. All these cases server to further racist and sexist stereotypes,
            and to blame is both the designers and the datasets.
        </p>
        <p>
            One of the biggest ai image generators, Stable Diffusion, uses LAION-5B as its dataset [3].
            LAION-5B collected its data automatically from across the web, without deference for the content or where it was being taken from.
            Using something so unfiltered is a massive cause for the bias built into the ai, and the curation and filtering of the dataset would likely have resulted in better results.
            There is an asterisk to this point, however, the people who curate the data must be diverse and show as little bias as possible.
            One great way of doing this would be to hire people of both diverse backgrounds and experiences, not just the average white American.
        </p>
        <h2>Outsourcing Work</h2>
        <p>
            There has been a major increase in outsourcing tech and data related jobs overseas to poorer nations [4] [5],
            and one of the main influences for this has been covid-19’s effect on remote work.
            Since companies have found they can employ people without having to provide office space for them, the question has come up,
            why do they need to hire locally? With this thought, there has been a rise in these jobs being sent to other countries,
            mainly ones where they can be paid far less than their local counterparts [5]. Despite the difference in pay, many take the jobs,
            as by the standards in their own country, the pay is more than liveable. This creates a unique situation, where these workers are,
            by definition, being exploited, but this is far better than the jobs not being outsourced, as the countries where these jobs go benefit majorly from this exploitation.

        </p>
        <p>
            As Amrute has stated, the work given from the western world to other countries is of the lesser kind, the inspiration, while the west are the experts doing the innovating [6].
            The work that is outsourced is generally less collaborative, although the shift with covid-19 has changed that slightly, so in years to come,
            this may be a great chance for the global south to have a voice in the digital sphere, until their own companies can grow to match the western ones.

        </p>
        <h2>Turning Exploitation into Opportunities</h2>
        <p>
            These jobs working for western companies, although exploitative, is the chance to force better representation into these fields.
            In both opinion and work done, there exists the opportunity to turn things, like the ai, into less biased systems and avoid the erasure and stereotyping of many cultures.
            Through this exploitation is the opportunity to make an impact on the system from within it, or at least that is the idea.
            Especially with the rise of ai development within South Africa [7], the bias within ai can be a thing of the past, along with enriching local economies.
            An ironic show of this was when amazon was using a team in India to supplement the ai in their checkout service [8] .

        </p>
        <h2>Conclusion</h2>
        <p>
            The current AI systems serve to further racist and sexist ideologies, and the only way to properly escape it, is to better the team developing the ai’s,
            with better representation and understanding to filter datasets. Through the outsourcing of tech based jobs,
            this may be possible, and although the labour is exploitative, it can be lucrative for these developing nations, like South Africa.
        </p>
        <h2>References</h2>
        <a href="https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/" class="url">[1] 	K. S. S. Y. C. Nitasha Tiku, “These fake images reveal how AI amplifies our worst stereotypes,” 1 November 2023.</a> <br />
        <a href="https://www.vox.com/2018/4/3/17168256/google-racism-algorithms-technology" class="url">[2] 	S. Illing, “How search engines are making us more racist,” 6 April 2018.</a> <br />
        <a href="https://www.bloomberg.com/graphics/2023-generative-ai-bias/" class="url">[3] 	D. B. Leonardo Nicoletti, “HUMANS ARE BIASED.,” 9 June 2023.</a> <br />
        <a href="https://www.cnbc.com/2024/05/01/google-cuts-hundreds-of-core-workers-moves-jobs-to-india-mexico.html" class="url">[4] 	J. Elias, “Google lays off hundreds of ‘Core’ employees, moves some positions to India and Mexico,” 2 May 2024.</a> <br />
        <a href="https://www.businessinsider.com/tech-silicon-valley-is-sending-jobs-abroad-2022-6" class="url">      [5] 	J. P. Erb, “Tech: Silicon Valley is sending jobs abroad,” 28 June 2022. </a> <br />
        <a href="" class="url">[6] 	S. Amrute, “Tech Colonialism Today,” 25 February 2020.</a> <br />
        <a href="https://www.itweb.co.za/article/ai-changes-the-world-and-sas-tech-jobs-market/KzQenMjyeyb7Zd2r" class="url">[7] 	S. Malinga, “AI changes the world and SA’s tech jobs market,” 7 March 2024.</a> <br />
        <a href="https://www.businessinsider.com/amazons-just-walk-out-actually-1-000-people-in-india-2024-4" class="url">[8] 	A. Bitter, “Amazon's Just Walk Out technology relies on hundreds of workers in India watching you shop,” 3 April 2024.</a>

    </div>
    <a href="essays.html" class="url"><< Back </a>

    <script type="module">

        import { initialise } from "../JavaScript/scroll.js"
        initialise()</script>


</body>

</html>